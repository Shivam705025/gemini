<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Video Analysis</title>
</head>
<body>
  <input type="file" accept="video/*" id="videoInput" />
  <video controls id="videoPlayer" style="width: 100%; max-width: 800px;"></video>
  <button onclick="processVideo()">Process Video</button>

  <script type="module">
          import {
        getGenerativeModel,
        updateUI,
      } from "./utils/shared.js";
    // Replace 'YOUR_API_KEY' with your actual API key
    const API_KEY = 'AIzaSyAnQWILIuamyHrwmVtp5EtqMGD3zFQC-rM';
    const prompt = "What's different between these pictures?";

    // Access your API key
    const genAI = new GoogleGenerativeAI(API_KEY);

    async function fileToGenerativePart(file) {
      const base64EncodedDataPromise = new Promise((resolve) => {
        const reader = new FileReader();
        reader.onloadend = () => resolve(reader.result.split(',')[1]);
        reader.readAsDataURL(file);
      });
      return {
        inlineData: { data: await base64EncodedDataPromise, mimeType: file.type },
      };
    }

    async function runAI(images) {
      // For text-and-images input (multimodal), use the gemini-pro-vision model
      const model = genAI.getGenerativeModel({ model: "gemini-pro-vision" });

      const imageParts = await Promise.all(images.map(fileToGenerativePart));

      const result = await model.generateContent([prompt, ...imageParts]);
      const response = await result.response;
      const text = response.text();
      console.log(text);
    }

    async function processVideo() {
      const videoInput = document.getElementById('videoInput');
      const videoPlayer = document.getElementById('videoPlayer');

      // Check if a file is selected
      if (videoInput.files.length > 0) {
        const videoFile = videoInput.files[0];

        // Set the video source
        videoPlayer.src = URL.createObjectURL(videoFile);

        // Play the video
        videoPlayer.play();

        // Extract frames from the video
        const frames = await extractFrames(videoFile);

        // Process frames using the AI model
        await runAI(frames);
      } else {
        alert('Please select a video file.');
      }
    }

    async function extractFrames(videoFile) {
      const videoPlayer = document.getElementById('videoPlayer');
      const canvas = document.createElement('canvas');
      const context = canvas.getContext('2d');

      const frames = [];

      return new Promise((resolve) => {
        videoPlayer.addEventListener('loadeddata', () => {
          const { videoWidth, videoHeight } = videoPlayer;
          canvas.width = videoWidth;
          canvas.height = videoHeight;

          const fps = 1; // Adjust as needed
          const interval = 1000 / fps;

          const captureFrame = () => {
            context.drawImage(videoPlayer, 0, 0, videoWidth, videoHeight);
            frames.push(canvas.toDataURL('image/jpeg'));
          };

          const captureInterval = setInterval(captureFrame, interval);

          videoPlayer.addEventListener('ended', () => {
            clearInterval(captureInterval);
            resolve(frames);
          });
        });

        videoPlayer.src = URL.createObjectURL(videoFile);
      });
    }
  </script>
</body>
</html>
