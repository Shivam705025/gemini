<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Video Analysis</title>
</head>
<body>
  <input type="file" accept="video/*" id="videoInput" />
  <video controls id="videoPlayer" style="width: 100%; max-width: 800px;"></video>
  <button onclick="processVideo()">Process Video</button>

      <script type="importmap">
      {
        "imports": {
          "@google/generative-ai": "https://esm.run/@google/generative-ai"
        }
      }
    </script>

  <script type="module">
    import { GoogleGenerativeAI } from "@google/generative-ai";
    // Replace 'YOUR_API_KEY' with your actual API key
    const API_KEY = 'AIzaSyAnQWILIuamyHrwmVtp5EtqMGD3zFQC-rM';
    const prompt = "What's different between these pictures?";

    // Access your API key
    const genAI = new GoogleGenerativeAI(API_KEY);

    async function fileToGenerativePart(file) {
      const base64EncodedDataPromise = new Promise((resolve) => {
        const reader = new FileReader();
        reader.onloadend = () => resolve(reader.result.split(',')[1]);
        reader.readAsDataURL(file);
      });
      return {
        inlineData: { data: await base64EncodedDataPromise, mimeType: file.type },
      };
    }

    async function runAI(images) {
      // For text-and-images input (multimodal), use the gemini-pro-vision model
      const model = genAI.getGenerativeModel({ model: "gemini-pro-vision" });

      const imageParts = await Promise.all(images.map(fileToGenerativePart));

      const result = await model.generateContent([prompt, ...imageParts]);
      const response = await result.response;
      const text = response.text();
      console.log(text);
    }
    
  </script>
  <script>
async function processVideo() {
  const imageInput = document.getElementById('imageInput');
  const imagePreview = document.getElementById('imagePreview');
  const videoPlayer = document.getElementById('videoPlayer');

  // Reset the video source and pause it
  videoPlayer.src = '';
  videoPlayer.pause();

  // Check if an image is selected
  if (imageInput.files.length > 0) {
    const imageFile = imageInput.files[0];

    // Display the image
    imagePreview.src = URL.createObjectURL(imageFile);

    // Reset the video source and pause it again
    videoPlayer.src = '';
    videoPlayer.pause();

    // Process the image using the AI model
    const images = [imageFile];
    await runAI(images);
  } else {
    alert('Please select an image file.');
  }
}

    async function extractFrames(videoFile) {
      const videoPlayer = document.getElementById('videoPlayer');
      const canvas = document.createElement('canvas');
      const context = canvas.getContext('2d');

      const frames = [];

      return new Promise((resolve) => {
        videoPlayer.addEventListener('loadeddata', () => {
          const { videoWidth, videoHeight } = videoPlayer;
          canvas.width = videoWidth;
          canvas.height = videoHeight;

          const fps = 1; // Adjust as needed
          const interval = 1000 / fps;

          const captureFrame = () => {
            context.drawImage(videoPlayer, 0, 0, videoWidth, videoHeight);
            frames.push(canvas.toDataURL('image/jpeg'));
          };

          const captureInterval = setInterval(captureFrame, interval);

          videoPlayer.addEventListener('ended', () => {
            clearInterval(captureInterval);
            resolve(frames);
          });
        });

        videoPlayer.src = URL.createObjectURL(videoFile);
      });
    }
  </script>
</body>
</html>
