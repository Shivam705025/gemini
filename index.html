<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Video Analysis</title>
</head>
<body>
  <input type="file" accept="video/*" id="videoInput" />
  <video controls id="videoPlayer" style="width: 100%; max-width: 800px;"></video>
  <button id="processButton">Process Video</button>
  <br>
  Result: <textarea id="resultTextArea" style="width: 100%; max-width: 800px; height: 100px;"></textarea>

  <script type="importmap">
    {
      "imports": {
        "@google/generative-ai": "https://esm.run/@google/generative-ai"
      }
    }
  </script>

<script type="module">
  import { GoogleGenerativeAI } from "@google/generative-ai";

  const API_KEY = 'AIzaSyAnQWILIuamyHrwmVtp5EtqMGD3zFQC-rM';
  const prompt = "What's different between these pictures?";

  // Access your API key
  const genAI = new GoogleGenerativeAI(API_KEY);

  async function fileToGenerativePart(file) {
    const base64EncodedDataPromise = new Promise((resolve) => {
      const reader = new FileReader();
      reader.onloadend = () => resolve(reader.result.split(',')[1]);
      reader.readAsDataURL(file);
    });
    return {
      inlineData: { data: await base64EncodedDataPromise, mimeType: file.type },
    };
  }


  async function runAI(images) {
    // For text-and-images input (multimodal), use the gemini-pro-vision model
    const model = genAI.getGenerativeModel({ model: "gemini-pro-vision" });

    const imageParts = await Promise.all(images.map(fileToGenerativePart));

    const result = await model.generateContent([prompt, ...imageParts]);
    const response = await result.response;
    const text = response.text();
    return text;
  }

  async function processVideo() {
    const videoInput = document.getElementById('videoInput');
    const videoPlayer = document.getElementById('videoPlayer');
    const resultTextArea = document.getElementById('resultTextArea');

    // Check if a video is selected
    if (videoInput.files.length > 0) {
      const videoFile = videoInput.files[0];

      // Pause the video
      videoPlayer.pause();

      // Set the video source
      videoPlayer.src = URL.createObjectURL(videoFile);

      // Load metadata to get video duration (optional)
      await videoPlayer.load();

      // Extract frames from the video
      const frames = await extractFrames(videoFile);

      // Process frames using the AI model
      const result = await runAI(frames);

      // Display result in the text area
      resultTextArea.value = result;

      // Play the video
      videoPlayer.play();
    } else {
      alert('Please select a video file.');
    }
  }

  async function extractFrames(videoFile) {
    const videoPlayer = document.getElementById('videoPlayer');
    const canvas = document.createElement('canvas');
    const context = canvas.getContext('2d');

    const frames = [];

    return new Promise((resolve) => {
      videoPlayer.addEventListener('loadeddata', () => {
        const { videoWidth, videoHeight } = videoPlayer;
        canvas.width = videoWidth;
        canvas.height = videoHeight;

        const fps = 1; // Adjust as needed
        const interval = 1000 / fps;

        const captureFrame = () => {
          context.drawImage(videoPlayer, 0, 0, videoWidth, videoHeight);
          frames.push(canvas.toDataURL('image/jpeg'));
        };

        const captureInterval = setInterval(captureFrame, interval);

        videoPlayer.addEventListener('ended', () => {
          clearInterval(captureInterval);
          resolve(frames);
        });
      });

      videoPlayer.src = URL.createObjectURL(videoFile);
    });
  }

  // Attach the event listener to the button
  const processButton = document.querySelector('button');
  processButton.addEventListener('click', processVideo);
</script>
</body>
</html>
